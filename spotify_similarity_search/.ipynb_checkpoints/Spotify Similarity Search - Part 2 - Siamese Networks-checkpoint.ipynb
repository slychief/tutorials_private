{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Similar Songs on Spotify - Part 2: Siamese Networks\n",
    "\n",
    "In the first part of this tutorial I have introduced the traditional distance based approach to similarity estimations. The main idea is that features are extracted from the audio content. These features are numeric descriptions of semantically relevant information. An example for a high-level feature is the number of beats per minute which is a description for the tempo of a song. Music feature-sets are more abstract and describe the spectral or rhythmical distribution of energy. These are not single but vectors of numbers. Thus, a song is semantically described by this vector and if the set of extracted features spans over various music characteristics such as rhythm, timbre, harmonics, complexity, etc. then calculating the similarity of the vector's numbers is considered to be an approximation of music similarity. Thus, the lower the numerical distance between two vectors, the higher their acoustic similarity. For this reason these approaches are known as *Distance based* methods. They mainly depend on the selected sets of features and on the similarity metric chosen to compare their values.\n",
    "\n",
    "In the second part of this tutorial we are now focussing on an approach, where the feature representation, as well as the similarity function is learned from the underlying dataset.\n",
    "\n",
    "\n",
    "## Tutorial Overview\n",
    "\n",
    "1. Loading data\n",
    "2. Preprocess data\n",
    "3. Define Model\n",
    "4. Fit Model\n",
    "5. Evaluate Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requiremnts\n",
    "\n",
    "The requirements are the same as for the first part of the tutorials. Please follow the instructions of part one if you have trouble running this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:32.488000Z",
     "start_time": "2017-08-24T10:20:32.483000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of tutorial_functions failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "NameError: name 'keras' is not defined\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# numeric and scientific processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import progressbar\n",
    "\n",
    "# spotify API\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "\n",
    "# local caching\n",
    "from joblib import Memory\n",
    "\n",
    "# functions from Tutorial Part 1\n",
    "import tutorial_functions as tut_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "We will use the same data that we downloaded from Spotify in Part 1 of the Tutorial. Because we used the joblib library, we will not have to wait that long, because the data is already cached on our harddrive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the following two variables according the credentials you received from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"SPOTIPY_CLIENT_ID\"]     = \"8a7fffc37b6c44e6b7bc344c3295034c\"\n",
    "os.environ[\"SPOTIPY_CLIENT_SECRET\"] = \"f19dd914ba58408c9407dd6479b23812\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same playlists as used in Part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playlists = [\n",
    "    \n",
    "     {\"name\": \"clubbeats\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DXbX3zSzB4MO0\"},\n",
    "     {\"name\": \"softpop\",      \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWTwnEm1IYyoj\"},\n",
    "     {\"name\": \"electropop\",   \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX4uPi2roRUwU\"},\n",
    "     {\"name\": \"rockclassics\", \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWXRqgorJj26U\"},\n",
    "     {\"name\": \"rockhymns\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX4vth7idTQch\"},\n",
    "     {\"name\": \"soft_rock\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX6xOPeSOGone\"},\n",
    "     {\"name\": \"metalcore\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWXIcbzpLauPS\"}, \n",
    "     {\"name\": \"metal\",        \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWWOaP4H0w5b0\"},\n",
    "     {\"name\": \"classic_metal\",\"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX2LTcinqsO68\"},\n",
    "     {\"name\": \"grunge\",       \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX11ghcIxjcjE\"},\n",
    "     {\"name\": \"hiphop\",       \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWVdgXTbYm2r0\"},\n",
    "     {\"name\": \"poppunk\",      \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DXa9wYJr1oMFq\"},\n",
    "     {\"name\": \"classic\",      \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DXcN1fAVSf7CR\"}\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:33.260000Z",
     "start_time": "2017-08-24T10:20:33.256000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token = util.prompt_for_user_token(\"slychief\", \n",
    "                                   \"playlist-modify-public\", \n",
    "                                   redirect_uri=\"http://localhost/\")\n",
    "\n",
    "sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the local chache directory. This should be the same as in Part 1 of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:32.875000Z",
     "start_time": "2017-08-24T10:20:32.870000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "memory = Memory(cachedir='/home/schindler/tmp/spotify/', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately I was not able to move this function to the tutorial_functions.py file, due to the @memory annotation. (If you know a way how to solve this, please create a Github-issue with your solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_spotify_data(track_id):\n",
    "    \n",
    "    # meta-data\n",
    "    track_metadata      = sp.track(track_id)\n",
    "    album_metadata      = sp.album(track_metadata[\"album\"][\"id\"])\n",
    "    artist_metadata     = sp.artist(track_metadata[\"artists\"][0][\"id\"])\n",
    "    \n",
    "    # feature-data\n",
    "    sequential_features = sp.audio_analysis(track_id)\n",
    "    trackbased_features = sp.audio_features([track_id])\n",
    "    \n",
    "    return track_metadata, album_metadata, artist_metadata, sequential_features, trackbased_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start loading the Spotify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% (962 of 986) |#################################################################################################################################################################################     | Elapsed Time: 0:00:41 ETA: 0:00:01"
     ]
    }
   ],
   "source": [
    "# Get Playlist meta-data\n",
    "playlists = tut_func.get_playlist_metadata(sp, playlists)\n",
    "\n",
    "# Get track-ids of all playlist entries\n",
    "playlists = tut_func.get_track_ids(sp, playlists)\n",
    "\n",
    "num_tracks_total = np.sum([playlist[\"num_tracks\"] for playlist in playlists])\n",
    "\n",
    "# Fetch data and features from Spotify\n",
    "pbar = progressbar.ProgressBar(max_value=num_tracks_total)\n",
    "pbar.start()\n",
    "\n",
    "raw_track_data      = []\n",
    "processed_track_ids = []\n",
    "\n",
    "for playlist in playlists:\n",
    "\n",
    "    for track_id in playlist[\"track_ids\"]:\n",
    "\n",
    "        try:\n",
    "            # avoid duplicates in the data-set\n",
    "            if track_id not in processed_track_ids:\n",
    "\n",
    "                # retrieve data from Spotify\n",
    "                spotify_data = get_spotify_data(track_id)\n",
    "\n",
    "                raw_track_data.append([playlist[\"name\"], spotify_data])\n",
    "                processed_track_ids.append(track_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print e\n",
    "\n",
    "        pbar.update(len(raw_track_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Networks\n",
    "\n",
    "A Siamese neural network is a neural network architecture where two inputs are fed into the same stack of network layers. This is where the name comes from. The shared layers are \"similar\" to Siamese Twins. By feeding two inputs to the shared layers, two representations are generated which can be used for comparison. To train the network according a certain task, it requires labelled data. To learn a simlarity function, these labels should indicate if the two input are similar or dissimilar.\n",
    "\n",
    "This is exactly the approach initially described by [TODO cite paper]\n",
    "The authors create pairs of simlar and dissimilar images. These are fed into a Siamese NEtwork stack. Finally, the model calculates the eucledian distance between the two generated representations. A contrastive loss is used, to optimize the learned simlarity.\n",
    "\n",
    "To calculate the similarity between a seed image and the rest of the collection, the model is applied to predict the distance between this seed image and every other. The result is a list of distances which has to be sorted descendingly.\n",
    "\n",
    "The following code example follows this approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras**\n",
    "\n",
    "We use the high-level deep learning API Keras. [TODO: link]\n",
    "\n",
    "[TODO: describe - auf Tom's Tutorial verweisen f√ºr instructoins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Nadam, SGD\n",
    "from keras.regularizers import l2, l1\n",
    "from keras import backend as K\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a distance measure to compare the two representations. We will be using the well known Eucledian distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the Siamese Network Ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_siamese_network(input_dim):\n",
    "\n",
    "    dense_1 = Dense(100, activation=\"selu\")\n",
    "    dense_2 = Dense(100, activation=\"selu\")\n",
    "    dense_3 = Dense(100, activation=\"selu\")\n",
    "\n",
    "    input_left  = Input(shape=input_dim)\n",
    "    input_right = Input(shape=input_dim)\n",
    "    \n",
    "    layers_left  = dense_1(dense_2(dense_3(input_left)))\n",
    "    layers_right = dense_1(dense_2(dense_3(input_right)))\n",
    "\n",
    "    distance = Lambda(euclidean_distance,\n",
    "                      output_shape=lambda x: x[0])([layers_left, layers_right])\n",
    "\n",
    "    model = Model([input_left, input_right], distance)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate feature-data\n",
    "\n",
    "Currently we only have a list of raw data-objects retrieved from the Spotify API. We need to transform this information to a more structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aggregate Meta-data\n",
    "metadata = tut_func.aggregate_metadata(raw_track_data)\n",
    "\n",
    "# Aggregate Feature-data\n",
    "feature_data = tut_func.aggregate_featuredata(raw_track_data, metadata)\n",
    "\n",
    "# standardize sequential_features\n",
    "feature_data -= feature_data.mean(axis=0)\n",
    "feature_data /= feature_data.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data-Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pairs(feature_data, metadata, num_pairs_per_track):\n",
    "    \n",
    "    data_pairs = []\n",
    "    labels     = []\n",
    "    \n",
    "    for row_id, q_track in metadata.sample(frac=1).iterrows():\n",
    "        \n",
    "        for _ in range(num_pairs_per_track):\n",
    "            \n",
    "            # search similar and dissimilar examples\n",
    "            pos_example = metadata[metadata.playlist == q_track.playlist].sample(1)\n",
    "            neg_example = metadata[metadata.playlist != q_track.playlist].sample(1)\n",
    "\n",
    "            # create feature pairs\n",
    "            data_pairs.append([feature_data[[row_id]][0], feature_data[[pos_example.index]][0]])\n",
    "            labels.append(1)\n",
    "\n",
    "            data_pairs.append([feature_data[[row_id]][0], feature_data[[neg_example.index]][0]])\n",
    "            labels.append(0)\n",
    "\n",
    "    return np.array(data_pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19240, 2, 69)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pairs, labels = create_pairs(feature_data, metadata, 10)\n",
    "\n",
    "data_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_siamese_network(data_pairs[:,0].shape[1:])\n",
    "\n",
    "# train\n",
    "rms = Nadam(lr=0.001)\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[\"mean_squared_error\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'PlotLosses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-b41495ebacf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           \u001b[0mcallbacks\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtut_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlotLosses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m           validation_split = 0.1)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'PlotLosses'"
     ]
    }
   ],
   "source": [
    "model.fit([data_pairs[:, 0], data_pairs[:, 1]], \n",
    "          labels, \n",
    "          batch_size       = 14, \n",
    "          verbose          = 0, \n",
    "          epochs           = 25, \n",
    "          callbacks        = [tut_func.PlotLosses()], \n",
    "          validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similar(query_idx, ascending=False):\n",
    "    res = [model.predict([feature_data[[query_idx]], feature_data[[i]]]) for i in range(feature_data.shape[0])]\n",
    "\n",
    "    res = np.array(res)\n",
    "    res = res.reshape(res.shape[0])\n",
    "\n",
    "    if ascending:\n",
    "        si = np.argsort(res)[::-1]\n",
    "    else:\n",
    "        si = np.argsort(res)\n",
    "\n",
    "    display_cols = [\"artist_name\", \"title\", \"album_name\", \"year\", \"playlist\"]\n",
    "    \n",
    "    print metadata.iloc[query_idx]\n",
    "\n",
    "    return metadata.loc[si, display_cols][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_id                                  3jJZVeExYzVYiV6Y9Fl3DX\n",
      "artist_name                                  Stone Temple Pilots\n",
      "title                                                      Plush\n",
      "album_name                                                  Core\n",
      "label                                                      Rhino\n",
      "duration                                                  310346\n",
      "popularity                                                    70\n",
      "year                                                        1992\n",
      "genres         [alternative metal, alternative rock, classic ...\n",
      "playlist                                                  grunge\n",
      "Name: 753, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Stone Temple Pilots</td>\n",
       "      <td>Plush</td>\n",
       "      <td>Core</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>Pearl Jam</td>\n",
       "      <td>State of Love and Trust</td>\n",
       "      <td>Singles - Original Motion Picture Soundtrack</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Soundgarden</td>\n",
       "      <td>Spoonman</td>\n",
       "      <td>Superunknown (20th Anniversary)</td>\n",
       "      <td>1994</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Alice In Chains</td>\n",
       "      <td>Man in the Box</td>\n",
       "      <td>Facelift</td>\n",
       "      <td>1990</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Sponge</td>\n",
       "      <td>Plowed</td>\n",
       "      <td>Rotting Pinata</td>\n",
       "      <td>1994</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Gruntruck</td>\n",
       "      <td>Crazy Love</td>\n",
       "      <td>Push</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Chris Cornell</td>\n",
       "      <td>Seasons</td>\n",
       "      <td>Singles - Original Motion Picture Soundtrack</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Alice In Chains</td>\n",
       "      <td>Would?</td>\n",
       "      <td>Dirt</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Love Battery</td>\n",
       "      <td>Between The Eyes</td>\n",
       "      <td>Between The Eyes</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>Stone Temple Pilots</td>\n",
       "      <td>Creep</td>\n",
       "      <td>Core</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist_name                    title  \\\n",
       "753  Stone Temple Pilots                    Plush   \n",
       "768            Pearl Jam  State of Love and Trust   \n",
       "759          Soundgarden                 Spoonman   \n",
       "760      Alice In Chains           Man in the Box   \n",
       "792               Sponge                   Plowed   \n",
       "809            Gruntruck               Crazy Love   \n",
       "797        Chris Cornell                  Seasons   \n",
       "747      Alice In Chains                   Would?   \n",
       "800         Love Battery         Between The Eyes   \n",
       "769  Stone Temple Pilots                    Creep   \n",
       "\n",
       "                                       album_name  year playlist  \n",
       "753                                          Core  1992   grunge  \n",
       "768  Singles - Original Motion Picture Soundtrack  1992   grunge  \n",
       "759               Superunknown (20th Anniversary)  1994   grunge  \n",
       "760                                      Facelift  1990   grunge  \n",
       "792                                Rotting Pinata  1994   grunge  \n",
       "809                                          Push  1992   grunge  \n",
       "797  Singles - Original Motion Picture Soundtrack  1992   grunge  \n",
       "747                                          Dirt  1992   grunge  \n",
       "800                              Between The Eyes  1992   grunge  \n",
       "769                                          Core  1992   grunge  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(753)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_id                                  3jJZVeExYzVYiV6Y9Fl3DX\n",
      "artist_name                                  Stone Temple Pilots\n",
      "title                                                      Plush\n",
      "album_name                                                  Core\n",
      "label                                                      Rhino\n",
      "duration                                                  310346\n",
      "popularity                                                    70\n",
      "year                                                        1992\n",
      "genres         [alternative metal, alternative rock, classic ...\n",
      "playlist                                                  grunge\n",
      "Name: 753, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>The Presidents Of The United States Of America</td>\n",
       "      <td>Peaches</td>\n",
       "      <td>The Presidents of The United States of America...</td>\n",
       "      <td>1995</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>Stone Temple Pilots</td>\n",
       "      <td>Creep</td>\n",
       "      <td>Core</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>The Presidents Of The United States Of America</td>\n",
       "      <td>Lump</td>\n",
       "      <td>The Presidents of The United States of America...</td>\n",
       "      <td>1995</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Seether</td>\n",
       "      <td>Fine Again</td>\n",
       "      <td>Disclaimer</td>\n",
       "      <td>2002</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Days Of The New</td>\n",
       "      <td>Shelf In The Room</td>\n",
       "      <td>The Definitive Collection</td>\n",
       "      <td>2008</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Malfunkshun</td>\n",
       "      <td>Jezebel Woman</td>\n",
       "      <td>Return To Olympus</td>\n",
       "      <td>1995</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Chris Cornell</td>\n",
       "      <td>Seasons</td>\n",
       "      <td>Singles - Original Motion Picture Soundtrack</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>The Smashing Pumpkins</td>\n",
       "      <td>Quiet</td>\n",
       "      <td>Siamese Dream (2011 - Remaster)</td>\n",
       "      <td>1993</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>Seaweed</td>\n",
       "      <td>Losing Skin</td>\n",
       "      <td>Four</td>\n",
       "      <td>1993</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>Mother Love Bone</td>\n",
       "      <td>Crown Of Thorns</td>\n",
       "      <td>Mother Love Bone</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        artist_name              title  \\\n",
       "787  The Presidents Of The United States Of America            Peaches   \n",
       "769                             Stone Temple Pilots              Creep   \n",
       "771  The Presidents Of The United States Of America               Lump   \n",
       "775                                         Seether         Fine Again   \n",
       "786                                 Days Of The New  Shelf In The Room   \n",
       "813                                     Malfunkshun      Jezebel Woman   \n",
       "797                                   Chris Cornell            Seasons   \n",
       "795                           The Smashing Pumpkins              Quiet   \n",
       "804                                         Seaweed        Losing Skin   \n",
       "806                                Mother Love Bone    Crown Of Thorns   \n",
       "\n",
       "                                            album_name  year playlist  \n",
       "787  The Presidents of The United States of America...  1995   grunge  \n",
       "769                                               Core  1992   grunge  \n",
       "771  The Presidents of The United States of America...  1995   grunge  \n",
       "775                                         Disclaimer  2002   grunge  \n",
       "786                          The Definitive Collection  2008   grunge  \n",
       "813                                  Return To Olympus  1995   grunge  \n",
       "797       Singles - Original Motion Picture Soundtrack  1992   grunge  \n",
       "795                    Siamese Dream (2011 - Remaster)  1993   grunge  \n",
       "804                                               Four  1993   grunge  \n",
       "806                                   Mother Love Bone  1992   grunge  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(753, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_siamese_network(input_dim, loss=\"mean_squared_error\"):\n",
    "\n",
    "    input_left  = Input(shape=input_dim)\n",
    "    input_right = Input(shape=input_dim)\n",
    "\n",
    "    dense_1 = Dense(100, activation=\"selu\")\n",
    "    dense_2 = Dense(100, activation=\"selu\")\n",
    "    dense_3 = Dense(100, activation=\"selu\")\n",
    "    \n",
    "    #network = dense_1(dense_2(dense_3))\n",
    "    \n",
    "    layers_left  = dense_1(dense_2(dense_3(input_left)))\n",
    "    layers_right = dense_1(dense_2(dense_3(input_right)))\n",
    "\n",
    "    L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "\n",
    "    distance = Lambda(L1_distance,\n",
    "                      output_shape=lambda x: x[0])([layers_left, layers_right])\n",
    "\n",
    "    prediction = Dense(100, activation=\"elu\")(distance)\n",
    "\n",
    "    prediction = Dense(1, activation=\"sigmoid\")(prediction)\n",
    "\n",
    "    model = Model([input_left, input_right], prediction)\n",
    "\n",
    "    # train\n",
    "    rms = Nadam(lr=0.001)\n",
    "    model.compile(loss=loss, optimizer=rms, metrics=[\"mean_squared_error\", \"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_id                                  3jJZVeExYzVYiV6Y9Fl3DX\n",
      "artist_name                                  Stone Temple Pilots\n",
      "title                                                      Plush\n",
      "album_name                                                  Core\n",
      "label                                                      Rhino\n",
      "duration                                                  310346\n",
      "popularity                                                    70\n",
      "year                                                        1992\n",
      "genres         [alternative metal, alternative rock, classic ...\n",
      "playlist                                                  grunge\n",
      "Name: 753, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Veruca Salt</td>\n",
       "      <td>Volcano Girls</td>\n",
       "      <td>Eight Arms To Hold You</td>\n",
       "      <td>1997</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Pearl Jam</td>\n",
       "      <td>Daughter (Remastered)</td>\n",
       "      <td>Vs.</td>\n",
       "      <td>1993</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>Silverchair</td>\n",
       "      <td>Suicidal Dream - Remastered</td>\n",
       "      <td>Frogstomp 20th Anniversary (Deluxe Edition [Re...</td>\n",
       "      <td>2015</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Nirvana</td>\n",
       "      <td>All Apologies</td>\n",
       "      <td>In Utero - 20th Anniversary Remaster</td>\n",
       "      <td>1993</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>The Smashing Pumpkins</td>\n",
       "      <td>Quiet</td>\n",
       "      <td>Siamese Dream (2011 - Remaster)</td>\n",
       "      <td>1993</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Hole</td>\n",
       "      <td>Celebrity Skin</td>\n",
       "      <td>Celebrity Skin</td>\n",
       "      <td>1998</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>L7</td>\n",
       "      <td>Pretend We're Dead</td>\n",
       "      <td>Bricks Are Heavy</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Gruntruck</td>\n",
       "      <td>Crazy Love</td>\n",
       "      <td>Push</td>\n",
       "      <td>1992</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Sponge</td>\n",
       "      <td>Plowed</td>\n",
       "      <td>Rotting Pinata</td>\n",
       "      <td>1994</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Jerry Cantrell</td>\n",
       "      <td>Cut You In</td>\n",
       "      <td>Boggy Depot</td>\n",
       "      <td>1998</td>\n",
       "      <td>grunge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist_name                        title  \\\n",
       "803            Veruca Salt                Volcano Girls   \n",
       "764              Pearl Jam        Daughter (Remastered)   \n",
       "777            Silverchair  Suicidal Dream - Remastered   \n",
       "758                Nirvana                All Apologies   \n",
       "795  The Smashing Pumpkins                        Quiet   \n",
       "772                   Hole               Celebrity Skin   \n",
       "799                     L7           Pretend We're Dead   \n",
       "809              Gruntruck                   Crazy Love   \n",
       "792                 Sponge                       Plowed   \n",
       "798         Jerry Cantrell                   Cut You In   \n",
       "\n",
       "                                            album_name  year playlist  \n",
       "803                             Eight Arms To Hold You  1997   grunge  \n",
       "764                                                Vs.  1993   grunge  \n",
       "777  Frogstomp 20th Anniversary (Deluxe Edition [Re...  2015   grunge  \n",
       "758               In Utero - 20th Anniversary Remaster  1993   grunge  \n",
       "795                    Siamese Dream (2011 - Remaster)  1993   grunge  \n",
       "772                                     Celebrity Skin  1998   grunge  \n",
       "799                                   Bricks Are Heavy  1992   grunge  \n",
       "809                                               Push  1992   grunge  \n",
       "792                                     Rotting Pinata  1994   grunge  \n",
       "798                                        Boggy Depot  1998   grunge  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(753, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_id                                  6DzuDDN9q4N29QXWDuQ8sx\n",
      "artist_name                                         Ugly Kid Joe\n",
      "title                                         Cats In The Cradle\n",
      "album_name                                America's Least Wanted\n",
      "label                   Digital Distribution Trinidad and Tobago\n",
      "duration                                                  242173\n",
      "popularity                                                    59\n",
      "year                                                        1992\n",
      "genres         [funk metal, glam metal, hard rock, post-grung...\n",
      "playlist                                               soft_rock\n",
      "Name: 470, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Ugly Kid Joe</td>\n",
       "      <td>Cats In The Cradle</td>\n",
       "      <td>America's Least Wanted</td>\n",
       "      <td>1992</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Hoobastank</td>\n",
       "      <td>The Reason</td>\n",
       "      <td>The Reason</td>\n",
       "      <td>2004</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Eric Clapton</td>\n",
       "      <td>My Father's Eyes</td>\n",
       "      <td>Forever Man</td>\n",
       "      <td>2015</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Whitesnake</td>\n",
       "      <td>Is This Love - 2007 Remastered Version</td>\n",
       "      <td>1987 (2007 Remaster)</td>\n",
       "      <td>1987</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Def Leppard</td>\n",
       "      <td>Hysteria 2013 (Re-Recorded Version) - Single</td>\n",
       "      <td>Hysteria 2013 (Re-Recorded Version) - Single</td>\n",
       "      <td>2013</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>Nothing Else Matters</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>1991</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>REO Speedwagon</td>\n",
       "      <td>Keep on Loving You - Remastered</td>\n",
       "      <td>Hi Infidelity (30th Anniversary Edition)</td>\n",
       "      <td>1980</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>Chris Isaak</td>\n",
       "      <td>Wicked Game - Remastered</td>\n",
       "      <td>Best Of Chris Isaak</td>\n",
       "      <td>2006</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>Keane</td>\n",
       "      <td>Somewhere Only We Know</td>\n",
       "      <td>Hopes And Fears</td>\n",
       "      <td>2004</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Foreigner</td>\n",
       "      <td>Urgent - 2008 Remastered Version</td>\n",
       "      <td>No End In Sight: The Very Best Of Foreigner</td>\n",
       "      <td>2008</td>\n",
       "      <td>soft_rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist_name                                         title  \\\n",
       "470    Ugly Kid Joe                            Cats In The Cradle   \n",
       "484      Hoobastank                                    The Reason   \n",
       "496    Eric Clapton                              My Father's Eyes   \n",
       "473      Whitesnake        Is This Love - 2007 Remastered Version   \n",
       "500     Def Leppard  Hysteria 2013 (Re-Recorded Version) - Single   \n",
       "465       Metallica                          Nothing Else Matters   \n",
       "453  REO Speedwagon               Keep on Loving You - Remastered   \n",
       "557     Chris Isaak                      Wicked Game - Remastered   \n",
       "526           Keane                        Somewhere Only We Know   \n",
       "527       Foreigner              Urgent - 2008 Remastered Version   \n",
       "\n",
       "                                       album_name  year   playlist  \n",
       "470                        America's Least Wanted  1992  soft_rock  \n",
       "484                                    The Reason  2004  soft_rock  \n",
       "496                                   Forever Man  2015  soft_rock  \n",
       "473                          1987 (2007 Remaster)  1987  soft_rock  \n",
       "500  Hysteria 2013 (Re-Recorded Version) - Single  2013  soft_rock  \n",
       "465                                     Metallica  1991  soft_rock  \n",
       "453      Hi Infidelity (30th Anniversary Edition)  1980  soft_rock  \n",
       "557                           Best Of Chris Isaak  2006  soft_rock  \n",
       "526                               Hopes And Fears  2004  soft_rock  \n",
       "527   No End In Sight: The Very Best Of Foreigner  2008  soft_rock  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(470, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(similarity_function, cut_off):\n",
    "\n",
    "    global dist\n",
    "    \n",
    "    all_precisions = []\n",
    "\n",
    "    for idx in metadata.index.values:\n",
    "\n",
    "        dist           = similarity_function(feature_data, feature_data[[idx]])\n",
    "        dist           = np.array(dist).reshape(len(dist))\n",
    "        similar_tracks = metadata.loc[np.argsort(dist)[:cut_off]]\n",
    "        same_label     = similar_tracks[\"playlist\"] == metadata.loc[idx, \"playlist\"]\n",
    "        precision      = same_label.sum() / float(cut_off)\n",
    "        all_precisions.append(precision)\n",
    "\n",
    "    all_precisions = np.array(all_precisions)\n",
    "\n",
    "    return all_precisions.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84168399168399166"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lambda x,y: [model.predict([x[[i]], y]) for i in range(feature_data.shape[0])], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91460498960498948"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lambda x,y: [model.predict([x[[i]], y]) for i in range(feature_data.shape[0])], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97505197505197505"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lambda x,y: [model.predict([x[[i]], y]) for i in range(feature_data.shape[0])], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playlist_names = [pl[\"name\"] for pl in playlists]\n",
    "\n",
    "playlist_similarities = pd.DataFrame(np.zeros((len(playlist_names),len(playlist_names))), \n",
    "                                     index   = playlist_names, \n",
    "                                     columns = playlist_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clubbeats</th>\n",
       "      <th>softpop</th>\n",
       "      <th>electropop</th>\n",
       "      <th>rockclassics</th>\n",
       "      <th>rockhymns</th>\n",
       "      <th>soft_rock</th>\n",
       "      <th>metalcore</th>\n",
       "      <th>metal</th>\n",
       "      <th>classic_metal</th>\n",
       "      <th>grunge</th>\n",
       "      <th>hiphop</th>\n",
       "      <th>poppunk</th>\n",
       "      <th>classic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clubbeats</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softpop</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electropop</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rockclassics</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rockhymns</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_rock</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metalcore</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classic_metal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grunge</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiphop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poppunk</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               clubbeats  softpop  electropop  rockclassics  rockhymns  \\\n",
       "clubbeats            1.0      0.4         0.8           0.0        0.0   \n",
       "softpop              0.4      1.0         0.4           0.0        0.0   \n",
       "electropop           0.8      0.4         1.0           0.0        0.0   \n",
       "rockclassics         0.0      0.0         0.0           1.0        0.7   \n",
       "rockhymns            0.0      0.0         0.0           0.7        1.0   \n",
       "soft_rock            0.0      0.2         0.0           0.3        0.3   \n",
       "metalcore            0.0      0.0         0.0           0.0        0.0   \n",
       "metal                0.0      0.0         0.0           0.0        0.0   \n",
       "classic_metal        0.0      0.0         0.0           0.0        0.0   \n",
       "grunge               0.0      0.0         0.0           0.0        0.2   \n",
       "hiphop               0.0      0.1         0.4           0.0        0.0   \n",
       "poppunk              0.0      0.0         0.0           0.4        0.5   \n",
       "classic              0.0      0.0         0.0           0.0        0.0   \n",
       "\n",
       "               soft_rock  metalcore  metal  classic_metal  grunge  hiphop  \\\n",
       "clubbeats            0.0        0.0    0.0            0.0     0.0     0.0   \n",
       "softpop              0.2        0.0    0.0            0.0     0.0     0.1   \n",
       "electropop           0.0        0.0    0.0            0.0     0.0     0.4   \n",
       "rockclassics         0.3        0.0    0.0            0.0     0.0     0.0   \n",
       "rockhymns            0.3        0.0    0.0            0.0     0.2     0.0   \n",
       "soft_rock            1.0        0.0    0.0            0.0     0.0     0.0   \n",
       "metalcore            0.0        1.0    0.7            0.6     0.0     0.0   \n",
       "metal                0.0        0.7    1.0            0.8     0.5     0.0   \n",
       "classic_metal        0.0        0.6    0.8            1.0     0.5     0.0   \n",
       "grunge               0.0        0.0    0.5            0.5     1.0     0.0   \n",
       "hiphop               0.0        0.0    0.0            0.0     0.0     1.0   \n",
       "poppunk              0.0        0.0    0.6            0.4     0.0     0.0   \n",
       "classic              0.0        0.0    0.0            0.0     0.0     0.0   \n",
       "\n",
       "               poppunk  classic  \n",
       "clubbeats          0.0      0.0  \n",
       "softpop            0.0      0.0  \n",
       "electropop         0.0      0.0  \n",
       "rockclassics       0.4      0.0  \n",
       "rockhymns          0.5      0.0  \n",
       "soft_rock          0.0      0.0  \n",
       "metalcore          0.0      0.0  \n",
       "metal              0.6      0.0  \n",
       "classic_metal      0.4      0.0  \n",
       "grunge             0.0      0.0  \n",
       "hiphop             0.0      0.0  \n",
       "poppunk            1.0      0.0  \n",
       "classic            0.0      1.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = [[[\"clubbeats\",    \"electropop\"],    0.8],\n",
    "       [[\"clubbeats\",    \"softpop\"],      0.4],\n",
    "       [[\"electropop\",   \"hiphop\"],      0.4],\n",
    "       [[\"softpop\",      \"soft_rock\"],      0.2],\n",
    "       [[\"softpop\",      \"electropop\"],      0.4],\n",
    "       [[\"softpop\",    \"hiphop\"],      0.1],\n",
    "       [[\"rockclassics\",    \"rockhymns\"],      0.7],\n",
    "       [[\"soft_rock\",    \"rockclassics\"],      0.3],\n",
    "       [[\"soft_rock\",    \"rockhymns\"],      0.3],\n",
    "       [[\"metalcore\",    \"metal\"],      0.7],\n",
    "       [[\"metalcore\",    \"classic_metal\"],      0.6],\n",
    "       [[\"metal\",    \"classic_metal\"],      0.8],\n",
    "       [[\"classic_metal\",    \"grunge\"],      0.5],\n",
    "       [[\"metal\",    \"grunge\"],      0.5],\n",
    "       [[\"rockhymns\",    \"grunge\"],      0.2],\n",
    "       [[\"poppunk\",    \"metal\"],      0.6],\n",
    "       [[\"poppunk\",    \"classic_metal\"],      0.4],\n",
    "       [[\"poppunk\",    \"rockhymns\"],      0.5],\n",
    "       [[\"poppunk\",    \"rockclassics\"],      0.4]\n",
    "     ]\n",
    "\n",
    "# self-similarity\n",
    "for i in range(len(playlist_names)):\n",
    "    for j in range(len(playlist_names)):\n",
    "        if i == j:\n",
    "            playlist_similarities.iloc[i,j] = 1.0\n",
    "\n",
    "for s in sim:\n",
    "    playlist_similarities.loc[s[0][0],s[0][1]] = s[1]\n",
    "    playlist_similarities.loc[s[0][1],s[0][0]] = s[1]\n",
    "\n",
    "playlist_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pairs_with_sims(feature_data, metadata, num_pairs_per_track, playlist_similarities):\n",
    "    \n",
    "    data_pairs = []\n",
    "    labels     = []\n",
    "    \n",
    "    for row_id, q_track in metadata.sample(frac=1).iterrows():\n",
    "        \n",
    "        for _ in range(num_pairs_per_track):\n",
    "            \n",
    "            # search similar and dissimilar examples\n",
    "            pos_example = metadata[metadata.playlist == q_track.playlist].sample(1)\n",
    "            neg_example = metadata[metadata.playlist != q_track.playlist].sample(1)\n",
    "\n",
    "            # create feature pairs\n",
    "            data_pairs.append([feature_data[[row_id]][0], feature_data[[pos_example.index]][0]])\n",
    "            labels.append(playlist_similarities.loc[q_track.playlist, pos_example.playlist])\n",
    "\n",
    "            data_pairs.append([feature_data[[row_id]][0], feature_data[[neg_example.index]][0]])\n",
    "            labels.append(playlist_similarities.loc[q_track.playlist, neg_example.playlist])\n",
    "\n",
    "    return np.array(data_pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pairs, labels = create_pairs_with_sims(feature_data, metadata, 10, playlist_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19240, 2, 69)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_siamese_network(data_pairs[:,0].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0941 - mean_squared_error: 0.0941 - acc: 0.7647     \n",
      "Epoch 2/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0619 - mean_squared_error: 0.0619 - acc: 0.8103     \n",
      "Epoch 3/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0478 - mean_squared_error: 0.0478 - acc: 0.8282     \n",
      "Epoch 4/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0368 - mean_squared_error: 0.0368 - acc: 0.8423     \n",
      "Epoch 5/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0298 - mean_squared_error: 0.0298 - acc: 0.8499     \n",
      "Epoch 6/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0243 - mean_squared_error: 0.0243 - acc: 0.8534     \n",
      "Epoch 7/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0196 - mean_squared_error: 0.0196 - acc: 0.8577     \n",
      "Epoch 8/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0171 - mean_squared_error: 0.0171 - acc: 0.8589     \n",
      "Epoch 9/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0128 - mean_squared_error: 0.0128 - acc: 0.8629     \n",
      "Epoch 10/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0111 - mean_squared_error: 0.0111 - acc: 0.8638     \n",
      "Epoch 11/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0091 - mean_squared_error: 0.0091 - acc: 0.8645     \n",
      "Epoch 12/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0083 - mean_squared_error: 0.0083 - acc: 0.8649     \n",
      "Epoch 13/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0075 - mean_squared_error: 0.0075 - acc: 0.8648     \n",
      "Epoch 14/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0064 - mean_squared_error: 0.0064 - acc: 0.8656     \n",
      "Epoch 15/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0056 - mean_squared_error: 0.0056 - acc: 0.8656     \n",
      "Epoch 16/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0051 - mean_squared_error: 0.0051 - acc: 0.8659     \n",
      "Epoch 17/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0060 - mean_squared_error: 0.0060 - acc: 0.8652     \n",
      "Epoch 18/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0045 - mean_squared_error: 0.0045 - acc: 0.8660     \n",
      "Epoch 19/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0044 - mean_squared_error: 0.0044 - acc: 0.8657     \n",
      "Epoch 20/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0038 - mean_squared_error: 0.0038 - acc: 0.8660     \n",
      "Epoch 21/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0033 - mean_squared_error: 0.0033 - acc: 0.8661     \n",
      "Epoch 22/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0037 - mean_squared_error: 0.0037 - acc: 0.8660     \n",
      "Epoch 23/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0025 - mean_squared_error: 0.0025 - acc: 0.8663     \n",
      "Epoch 24/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0033 - mean_squared_error: 0.0033 - acc: 0.8660     \n",
      "Epoch 25/25\n",
      "19240/19240 [==============================] - 0s - loss: 0.0039 - mean_squared_error: 0.0039 - acc: 0.8659     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f814a044e90>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([data_pairs[:, 0], data_pairs[:, 1]], labels, batch_size=24, verbose=1, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94339916839916838"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lambda x,y: [model.predict([x[[i]], y]) for i in range(feature_data.shape[0])], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pairs_with_sims_and_identity(feature_data, metadata, num_pairs_per_track, playlist_similarities):\n",
    "    \n",
    "    data_pairs = []\n",
    "    labels     = []\n",
    "    \n",
    "    for row_id, q_track in metadata.sample(frac=1).iterrows():\n",
    "        \n",
    "        data_pairs.append([feature_data[[row_id]][0], feature_data[[row_id]][0]])\n",
    "        labels.append(1)\n",
    "        \n",
    "        for _ in range(num_pairs_per_track):\n",
    "            \n",
    "            # search similar and dissimilar examples\n",
    "            pos_example = metadata[metadata.playlist == q_track.playlist].sample(1)\n",
    "            neg_example = metadata[metadata.playlist != q_track.playlist].sample(1)\n",
    "\n",
    "            # create feature pairs\n",
    "            data_pairs.append([feature_data[[row_id]][0], feature_data[[pos_example.index]][0]])\n",
    "            labels.append(playlist_similarities.loc[q_track.playlist, pos_example.playlist] - 0.1)\n",
    "\n",
    "            data_pairs.append([feature_data[[row_id]][0], feature_data[[neg_example.index]][0]])\n",
    "            labels.append(playlist_similarities.loc[q_track.playlist, neg_example.playlist] - 0.1)\n",
    "\n",
    "    return np.array(data_pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pairs, labels = create_pairs_with_sims_and_identity(feature_data, metadata, 10, playlist_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_siamese_network(data_pairs[:,0].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0949 - mean_squared_error: 0.0949 - acc: 0.0540     \n",
      "Epoch 2/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0589 - mean_squared_error: 0.0589 - acc: 0.0551     \n",
      "Epoch 3/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0447 - mean_squared_error: 0.0447 - acc: 0.0560     \n",
      "Epoch 4/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0336 - mean_squared_error: 0.0336 - acc: 0.0564     \n",
      "Epoch 5/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0268 - mean_squared_error: 0.0268 - acc: 0.0569     \n",
      "Epoch 6/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0217 - mean_squared_error: 0.0217 - acc: 0.0570     \n",
      "Epoch 7/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0175 - mean_squared_error: 0.0175 - acc: 0.0571     \n",
      "Epoch 8/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0152 - mean_squared_error: 0.0152 - acc: 0.0572     \n",
      "Epoch 9/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0133 - mean_squared_error: 0.0133 - acc: 0.0572     \n",
      "Epoch 10/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0118 - mean_squared_error: 0.0118 - acc: 0.0572     \n",
      "Epoch 11/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0104 - mean_squared_error: 0.0104 - acc: 0.0572     \n",
      "Epoch 12/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0094 - mean_squared_error: 0.0094 - acc: 0.0572     \n",
      "Epoch 13/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0097 - mean_squared_error: 0.0097 - acc: 0.0572     \n",
      "Epoch 14/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0083 - mean_squared_error: 0.0083 - acc: 0.0572     \n",
      "Epoch 15/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0077 - mean_squared_error: 0.0077 - acc: 0.0572     \n",
      "Epoch 16/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0080 - mean_squared_error: 0.0080 - acc: 0.0572     \n",
      "Epoch 17/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0081 - mean_squared_error: 0.0081 - acc: 0.0572     \n",
      "Epoch 18/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0066 - mean_squared_error: 0.0066 - acc: 0.0572     \n",
      "Epoch 19/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0066 - mean_squared_error: 0.0066 - acc: 0.0572     \n",
      "Epoch 20/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0069 - mean_squared_error: 0.0069 - acc: 0.0572     \n",
      "Epoch 21/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0065 - mean_squared_error: 0.0065 - acc: 0.0572     \n",
      "Epoch 22/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0057 - mean_squared_error: 0.0057 - acc: 0.0572     \n",
      "Epoch 23/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0057 - mean_squared_error: 0.0057 - acc: 0.0572     \n",
      "Epoch 24/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0060 - mean_squared_error: 0.0060 - acc: 0.0572     \n",
      "Epoch 25/25\n",
      "20202/20202 [==============================] - 0s - loss: 0.0063 - mean_squared_error: 0.0063 - acc: 0.0572     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8139010e90>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([data_pairs[:, 0], data_pairs[:, 1]], labels, batch_size=24, verbose=1, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84655720338983054"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lambda x,y: [model.predict([x[[i]], y]) for i in range(feature_data.shape[0])], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_features_sequential(seq_data, track_data, len_segment, m_data, with_year=False, with_popularity=False):\n",
    "    \n",
    "    # sequential data\n",
    "    segments = seq_data[\"segments\"]\n",
    "    sl       = len(segments)\n",
    "    \n",
    "    mfcc              = np.array([s[\"timbre\"]            for s in segments])\n",
    "    chroma            = np.array([s[\"pitches\"]           for s in segments])\n",
    "    loudness_max      = np.array([s[\"loudness_max\"]      for s in segments]).reshape((sl,1))\n",
    "    loudness_start    = np.array([s[\"loudness_start\"]    for s in segments]).reshape((sl,1))\n",
    "    loudness_max_time = np.array([s[\"loudness_max_time\"] for s in segments]).reshape((sl,1))\n",
    "    duration          = np.array([s[\"duration\"]          for s in segments]).reshape((sl,1))\n",
    "    confidence        = np.array([s[\"confidence\"]        for s in segments]).reshape((sl,1))\n",
    "    \n",
    "    # concatenate sequential features\n",
    "    sequential_features = np.concatenate([mfcc, chroma, loudness_max, loudness_start, \n",
    "                                          loudness_max_time, duration, confidence], axis=1)\n",
    "    \n",
    "    offset  = np.random.randint(0, sl - len_segment)\n",
    "    segment = sequential_features[offset:(offset+len_segment),:]\n",
    "        \n",
    "    # track-based data\n",
    "    track_features = [track_data[0][\"acousticness\"],     # acoustic or not?\n",
    "                      track_data[0][\"danceability\"],     # danceable?\n",
    "                      track_data[0][\"energy\"],           # energetic or calm?\n",
    "                      track_data[0][\"instrumentalness\"], # is somebody singing?\n",
    "                      track_data[0][\"liveness\"],         # live or studio?\n",
    "                      track_data[0][\"speechiness\"],      # rap or singing?\n",
    "                      track_data[0][\"tempo\"],            # slow or fast?\n",
    "                      track_data[0][\"time_signature\"],   # 3/4, 4/4, 6/8, etc.\n",
    "                      track_data[0][\"valence\"]]          # happy or sad?\n",
    "    \n",
    "    if with_year:\n",
    "        track_features.append(int(m_data[\"year\"]))\n",
    "        \n",
    "    if with_popularity:\n",
    "        track_features.append(int(m_data[\"popularity\"]))\n",
    "        \n",
    "    \n",
    "    return segment, track_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential_features.shape: (962, 20, 29)\n",
      "trackbased_features.shape: (962, 11)\n"
     ]
    }
   ],
   "source": [
    "len_segment = 20\n",
    "\n",
    "sequential_features = []\n",
    "trackbased_features = []\n",
    "\n",
    "for i, (_, spotify_data) in enumerate(raw_track_data):\n",
    "    \n",
    "    _, _, _, f_sequential, f_trackbased = spotify_data\n",
    "    \n",
    "    seq_feat, track_feat = aggregate_features_sequential(f_sequential, \n",
    "                                                         f_trackbased, \n",
    "                                                         len_segment, \n",
    "                                                         metadata.loc[i],\n",
    "                                                         with_year=True,\n",
    "                                                         with_popularity=True)\n",
    "    \n",
    "    sequential_features.append(seq_feat)\n",
    "    trackbased_features.append(track_feat)\n",
    "    \n",
    "sequential_features = np.asarray(sequential_features)\n",
    "trackbased_features = np.asarray(trackbased_features)\n",
    "\n",
    "print \"sequential_features.shape:\", sequential_features.shape\n",
    "print \"trackbased_features.shape:\", trackbased_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize sequential_features\n",
    "rows, x, y = sequential_features.shape\n",
    "sequential_features = sequential_features.reshape(rows, (x * y))\n",
    "sequential_features -= sequential_features.mean(axis=0)\n",
    "sequential_features /= sequential_features.std(axis=0)\n",
    "sequential_features = sequential_features.reshape(rows, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize trackbased_features\n",
    "trackbased_features -= trackbased_features.mean(axis=0)\n",
    "trackbased_features /= trackbased_features.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pairs_with_sims_and_identity_segments(sequential_features, trackbased_features, metadata, num_pairs_per_track, playlist_similarities):\n",
    "    \n",
    "    data_pairs_seq   = []\n",
    "    data_pairs_track = []\n",
    "    labels           = []\n",
    "    \n",
    "    for row_id, q_track in metadata.sample(frac=1).iterrows():\n",
    "        \n",
    "        data_pairs_seq.append([sequential_features[[row_id]][0], sequential_features[[row_id]][0]])\n",
    "        data_pairs_track.append([trackbased_features[[row_id]][0], trackbased_features[[row_id]][0]])\n",
    "        labels.append(1)\n",
    "        \n",
    "        for _ in range(num_pairs_per_track):\n",
    "            \n",
    "            # search similar and dissimilar examples\n",
    "            pos_example = metadata[metadata.playlist == q_track.playlist].sample(1)\n",
    "            neg_example = metadata[metadata.playlist != q_track.playlist].sample(1)\n",
    "\n",
    "            # create feature pairs\n",
    "            data_pairs_seq.append([sequential_features[[row_id]][0], sequential_features[[pos_example.index]][0]])\n",
    "            data_pairs_track.append([trackbased_features[[row_id]][0], trackbased_features[[pos_example.index]][0]])\n",
    "            labels.append(playlist_similarities.loc[q_track.playlist, pos_example.playlist] - 0.1)\n",
    "\n",
    "            data_pairs_seq.append([sequential_features[[row_id]][0], sequential_features[[neg_example.index]][0]])\n",
    "            data_pairs_track.append([trackbased_features[[row_id]][0], trackbased_features[[neg_example.index]][0]])\n",
    "            labels.append(playlist_similarities.loc[q_track.playlist, neg_example.playlist] - 0.1)\n",
    "\n",
    "    return np.array(data_pairs_seq), np.array(data_pairs_track), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pairs_seq, data_pairs_track, labels = create_pairs_with_sims_and_identity_segments(sequential_features,\n",
    "                                                                                        trackbased_features,\n",
    "                                                                                        metadata, \n",
    "                                                                                        10, \n",
    "                                                                                        playlist_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional, Input, Lambda\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda,Convolution1D\n",
    "from keras.optimizers import RMSprop, Nadam, SGD\n",
    "from keras.regularizers import l2, l1\n",
    "from keras import backend as K\n",
    "#from keras.constraint import unit_norm\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = data_pairs_seq[:, 0].shape[1:]\n",
    "\n",
    "input_a = Input(shape=data_pairs_seq[:, 0].shape[1:])\n",
    "input_b = Input(shape=data_pairs_seq[:, 0].shape[1:])\n",
    "input_a2 = Input(shape=data_pairs_track[:, 0].shape[1:])\n",
    "input_b2 = Input(shape=data_pairs_track[:, 0].shape[1:])\n",
    "\n",
    "bdlstm = Bidirectional(LSTM(29, return_sequences=False, activation=\"selu\"))\n",
    "\n",
    "processed_a = bdlstm(input_a)\n",
    "processed_b = bdlstm(input_b)\n",
    "\n",
    "dens = Dense(9, activation=\"selu\")\n",
    "\n",
    "processed_a2 = dens(input_a2)\n",
    "processed_b2 = dens(input_b2)\n",
    "\n",
    "left = concatenate([processed_a, processed_a2], axis=1)\n",
    "right = concatenate([processed_b, processed_b2], axis=1)\n",
    "\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "\n",
    "distance = Lambda(L1_distance,\n",
    "                  output_shape=lambda x: x[0])([left, right])\n",
    "\n",
    "prediction = Dense(29 + 9, activation=\"elu\")(distance)\n",
    "#prediction = Dense(64, activation=\"elu\")(prediction)\n",
    "\n",
    "prediction = Dense(1, activation=\"sigmoid\")(prediction)\n",
    "\n",
    "model = Model([input_a, input_b, input_a2, input_b2], prediction)\n",
    "\n",
    "# train\n",
    "rms = Nadam(lr=0.001)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=rms, metrics=[\"mean_squared_error\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-5409d96d8e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_pairs_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_pairs_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_pairs_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_pairs_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1575\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1576\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    965\u001b[0m                                                  \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m                                                  **self._function_kwargs)\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Invalid argument \"%s\" passed to K.function with Theano backend'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   1215\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m                                         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1793\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             defaults)\n\u001b[0m\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[1;32m   1659\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[0;32m-> 1661\u001b[0;31m                 input_storage=input_storage_lists, storage_map=storage_map)\n\u001b[0m\u001b[1;32m   1662\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[1;32m    697\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[1;32m    698\u001b[0m                              \u001b[0moutput_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                              storage_map=storage_map)[:3]\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/vm.pyc\u001b[0m in \u001b[0;36mmake_all\u001b[0;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                                                  \u001b[0mno_recycling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                                                  impl=impl))\n\u001b[0m\u001b[1;32m   1048\u001b[0m                 \u001b[0mlinker_make_thunk_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthunk_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lazy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 935\u001b[0;31m                                          no_recycling)\n\u001b[0m\u001b[1;32m    936\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;31m# We requested the c code, so don't catch the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[0;32m--> 839\u001b[0;31m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0mfill_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         cthunk, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[1;32m   1189\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36m__compile__\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                                     \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                                     \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                                     keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return (thunk,\n\u001b[1;32m   1133\u001b[0m                 [link.Container(input, storage) for input, storage in\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mcthunk_factory\u001b[0;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[0;32m-> 1586\u001b[0;31m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m         \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cmodule.pyc\u001b[0m in \u001b[0;36mmodule_from_key\u001b[0;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[1;32m   1157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m   1487\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m                 preargs=preargs)\n\u001b[0m\u001b[1;32m   1490\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cmodule.pyc\u001b[0m in \u001b[0;36mcompile_str\u001b[0;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[1;32m   2292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2294\u001b[0;31m             \u001b[0mp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_subprocess_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2295\u001b[0m             \u001b[0mcompile_stderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/misc/windows.pyc\u001b[0m in \u001b[0;36moutput_subprocess_Popen\u001b[0;34m(command, **params)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# we need to use communicate to make sure we don't deadlock around\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# the stdout/stderr pipe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_has_poll\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_with_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_with_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m_communicate_with_poll\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1469\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mfd2file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([data_pairs_seq[:, 0], data_pairs_seq[:, 1], data_pairs_track[:,0], data_pairs_track[:,1]], labels, batch_size=24, verbose=1, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(similarity_function, cut_off):\n",
    "\n",
    "    all_precisions = []\n",
    "    \n",
    "    pbar = progressbar.ProgressBar()\n",
    "\n",
    "    for idx in pbar(metadata.index.values):\n",
    "\n",
    "        dist           = similarity_function(sequential_features, sequential_features[[idx]], trackbased_features, trackbased_features[[idx]])\n",
    "        dist           = np.array(dist).reshape(len(dist))\n",
    "        similar_tracks = metadata.loc[np.argsort(dist)[::-1][:cut_off]]\n",
    "        same_label     = similar_tracks[\"playlist\"] == metadata.loc[idx, \"playlist\"]\n",
    "        precision      = same_label.sum() / float(cut_off)\n",
    "        all_precisions.append(precision)\n",
    "\n",
    "    all_precisions = np.array(all_precisions)\n",
    "\n",
    "    return all_precisions.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (944 of 944) |#####################################################################################################################################################################################| Elapsed Time: 1:20:00 Time: 1:20:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85317796610169494"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lambda w,x,y,z: [model.predict([w[[i]],x,y[[i]],z]) for i in range(sequential_features.shape[0])], 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "notify_time": "5",
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
